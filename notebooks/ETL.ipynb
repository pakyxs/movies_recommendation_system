{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRABAJAMOS SOBRE EL MOVIES_DATASET.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias para poder trabajar con los datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from sklearn.metrics.pairwise import sigmoid_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el dataset credits y los convertimos a dataframe para poder trabajar con él\n",
    "df_movies = pd.read_csv(\"../datasets/raw/movies_dataset.csv\", sep=\",\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observando los datos anteriores decido trabajar sobre estas columnas\n",
    "columns_to_transform = [\n",
    "    \"belongs_to_collection\",\n",
    "    \"genres\",\n",
    "    \"production_companies\",\n",
    "    \"production_countries\",\n",
    "    \"spoken_languages\",\n",
    "    \"id\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trabajamos sobre la columna belongs_to_collection\n",
    "df = df_movies  # Crea un dataframe para trabajar sobre este y no sobre el original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos las filas duplicadas en base al id\n",
    "df.drop_duplicates(subset='id', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Creamos una funcion para hacer una evaluacion literal de las filas que se le asigne\n",
    "def transform_row(row):\n",
    "    \"\"\"\n",
    "    Esta funcion toma una fila, si es de tipo string que contiene una representación literal de un objeto de datos de Python,\n",
    "     como un diccionario, una lista, una tupla, un conjunto, un número o una cadena, y la interpreta como el objeto real en memoria.\n",
    "    \"\"\"\n",
    "    if isinstance(row, str):  # Checkeamos si la fila es de formato string\n",
    "        try:\n",
    "            evaluation = ast.literal_eval(row)  # Convertimos el string a diccionario\n",
    "            return evaluation\n",
    "        except (SyntaxError, ValueError):\n",
    "            return None  # Devuelve None si el string no puede ser convertido en diccionario\n",
    "    return np.nan  # Retorna NaN si es el valor es NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorremos las columnas que decidimos transformar y aplica la funcion transform_now\n",
    "for column in columns_to_transform:\n",
    "    transformed_column = [\n",
    "        transform_row(row) for row in df[column]\n",
    "    ]  # Aplicamos la funcion en cada fila de la columna y la guarda en una variable en formato lista\n",
    "    df[\n",
    "        column\n",
    "    ] = transformed_column  # Guardamos la lista creada anteriormente a la columna belongs_to_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenamos los valores NaN por el valor 0 de las columnas revenue y budget\n",
    "df[\"revenue\"] = df[\"revenue\"].fillna(0)\n",
    "df[\"budget\"] = df[\"budget\"].fillna(0)\n",
    "# Rellenamos los valores NaN por el string 0 de la columna overview porque después vamos a usar un modelo que no acepta enteros\n",
    "df[\"overview\"] = df[\"overview\"].fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removemos las filas con valores nulos en la columna release_date\n",
    "# Iteramos sobre los valores de la columna release_date\n",
    "for index, value in df[\"release_date\"].items():\n",
    "    if pd.isna(value):\n",
    "        df.drop(index, inplace=True)\n",
    "\n",
    "# Reseteamos los indices del dataframe\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Reemplazamos no-infinitos valores por 0\n",
    "df[\"release_date\"].replace([np.nan, np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "# Encontramos los índices donde el valor es cero\n",
    "indices_cero = df.loc[df[\"release_date\"] == 0].index\n",
    "print(indices_cero)\n",
    "# Borramos las filas con los índices encontrados\n",
    "df.drop(indices_cero, inplace=True)\n",
    "\n",
    "# Reseteamos los indices del dataframe\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos la columna de fechas al formato AAAA-mm-dd\n",
    "df[\"release_date\"] = pd.to_datetime(\n",
    "    df[\"release_date\"], errors=\"coerce\", format=\"%Y-%m-%d\"\n",
    ")\n",
    "df[\"release_date\"] = df[\"release_date\"].dt.date\n",
    "\n",
    "# Extraemos el año de la columna release_date y lo guarda en una nueva columna llamada release_year\n",
    "df[\"release_year\"] = pd.to_datetime(df[\"release_date\"]).dt.year\n",
    "\n",
    "# Reemplazamos no-infinitos valores por 0\n",
    "df[\"release_year\"].replace([np.nan, np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "# Encontramos los índices donde el valor es cero\n",
    "indices_cero = df.loc[df[\"release_year\"] == 0].index\n",
    "\n",
    "# Borramos las filas con los índices encontrados\n",
    "df.drop(indices_cero, inplace=True)\n",
    "\n",
    "# Reseteamos los indices del dataframe\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convertimos la columna a números enteros\n",
    "df[\"release_year\"] = df[\"release_year\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la columna return que se calcula como el revenue sobre budget\n",
    "\n",
    "# Transformamos los datos a tipo float para poder usarlos en operaciones matemáticas\n",
    "df[\"budget\"] = df[\"budget\"].astype(float)\n",
    "df[\"revenue\"] = df[\"revenue\"].astype(float)\n",
    "\n",
    "df[\"return\"] = df[\"revenue\"] / df[\"budget\"]  # Calculamos el return\n",
    "\n",
    "# Reemplazamos los NaN (ocurre cuando el valor de revenue es 0) y los infinitos (ocurre cuando el valor de buget es 0) por el valor 0.\n",
    "df[\"return\"].replace([np.nan, np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las columnas que no son reelevantes para este proyecto\n",
    "columns_to_delete = [\n",
    "    \"video\",\n",
    "    \"imdb_id\",\n",
    "    \"adult\",\n",
    "    \"original_title\",\n",
    "    \"poster_path\",\n",
    "    \"homepage\",\n",
    "    \"belongs_to_collection\",\n",
    "    \"genres\",\n",
    "    \"original_language\",\n",
    "    \"production_companies\",\n",
    "    \"production_countries\",\n",
    "    \"spoken_languages\",\n",
    "    \"status\",\n",
    "    \"tagline\",\n",
    "    \"runtime\"\n",
    "\n",
    "]\n",
    "df = df.drop(columns=columns_to_delete)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRABAJAMOS SOBRE CREDITS.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos el dataset credits y los convertimos a dataframe para poder trabajar con él\n",
    "df_credits = pd.read_csv(\"../datasets/raw/credits.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_dict(df_name):\n",
    "    \"\"\"\n",
    "        Esta funcion toma una fila, si es de tipo string que contiene una representación literal de un objeto de datos de Python,\n",
    "     como un diccionario, una lista, una tupla, un conjunto, un número o una cadena, y la interpreta como el objeto real en memoria. Exceptúa la columna 'id'.\n",
    "\n",
    "    \"\"\"\n",
    "    for column in df_name:\n",
    "        if column == 'id':\n",
    "            None\n",
    "        else:\n",
    "            # Evaluamos las filas del dataframe y las transformamos\n",
    "            df = df_name\n",
    "            df[column] = df_credits[column].apply(lambda x: eval(x))\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos las filas del dataframe df_credits\n",
    "df_credits_evaluated = row_to_dict(df_credits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnest_columns(df,column,fixed_column,new_fixed_column_name):\n",
    "    '''Esta función toma una columna (column) que contenga una lista de disccionarios, de un dataframe (df) y las desanida. \n",
    "    Crea un nuevo dataframe (new_df) tomando cada key del diccionario como nombre de columna en el nuevo dataframe y \n",
    "    dejando fijo el valor de una columna (fixed_column), nombrandola segun el input new_fixed_column_name.\n",
    "    column, fixed_column y new_fixed_column_name deben ingresarse en formato string.\n",
    "     '''\n",
    "     # Creamos una nueva lista para almacenar los diccionarios desanidados\n",
    "    diccionarios_desanidados = []\n",
    "\n",
    "    # Iteramos sobre cada fila de la columna 'columna_lista'\n",
    "    for lista_diccionarios,movieid in zip(df[column],df[fixed_column]):\n",
    "        # Iteramos sobre cada diccionario en la lista\n",
    "        for diccionario in lista_diccionarios:\n",
    "            # Agregamos cada diccionario a la lista de diccionarios desanidados\n",
    "            diccionario[new_fixed_column_name] = movieid\n",
    "            diccionarios_desanidados.append(diccionario)\n",
    "                    \n",
    "\n",
    "    # Creamos un nuevo DataFrame con los diccionarios desanidados\n",
    "    new_df = pd.DataFrame(diccionarios_desanidados)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desanidamos la columna cast del df_credits_evaluated y lo guardamos en el dataframe df_unnested_cast\n",
    "df_unnested_cast = unnest_columns(df_credits_evaluated, 'cast', 'id', 'movie_id')\n",
    "\n",
    "# Desanidamos la columna cast del df_credits_evaluated y lo guardamos en el dataframe df_unnested_crew\n",
    "df_unnested_crew = unnest_columns(df_credits_evaluated, 'crew', 'id', 'movie_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las columnas que no son reelevantes para este proyecto del dataframe cast\n",
    "columns_to_delete_cast = [\n",
    "    \"cast_id\",\n",
    "    \"character\",\n",
    "    \"credit_id\",\n",
    "    \"gender\",\n",
    "    \"order\",\n",
    "    \"profile_path\",\n",
    "\n",
    "]\n",
    "df_cast = df_unnested_cast.drop(columns=columns_to_delete_cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtramos las filas del df_unnested_crew donde el trabajo es director y lo guardamos en un dataframe llamado df_director\n",
    "df_director = df_unnested_crew[df_unnested_crew['job'] == 'Director']  \n",
    "\n",
    "#Eliminamos las columnas que no son reelevantes para este proyecto del dataframe df_director\n",
    "columns_to_delete_director = [\n",
    "    \"credit_id\",\n",
    "    \"department\",\n",
    "    \"gender\",\n",
    "    \"job\",\n",
    "    \"profile_path\",\n",
    "\n",
    "]\n",
    "df_director = df_director.drop(columns=columns_to_delete_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un dataframe de muestra para reducir el tiempo de procesamiento ya que la capacidad de render es limitada\n",
    "sample = df.sample(n=1000, random_state=42).reset_index(drop=True)  # n es el número de filas de la muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos los csv en base a los dataframes creado\n",
    "df_cast.to_csv('../datasets/model/cast.csv', index=False)\n",
    "df_director.to_csv('../datasets/model/director.csv', index=False)\n",
    "df.to_csv('../datasets/model/movies.csv', index=False)\n",
    "sample.to_csv('../datasets/model/sample.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
